#!/usr/bin/python
# -*- coding: utf-8 -*-

#    PyInteraph, a software suite to analyze interactions and interaction network in structural ensembles.
#    Copyright (C) 2013 Matteo Tiberti <matteo.tiberti@gmail.com>, Gaetano Invernizzi, Yuval Inbar, 
#    Matteo Lambrughi, Gideon Schreiber, Â Elena Papaleo <elena.papaleo@unimib.it> <elena.papaleo@bio.ku.dk>
#
#    This program is free software: you can redistribute it and/or modify
#    it under the terms of the GNU General Public License as published by
#    the Free Software Foundation, either version 3 of the License, or
#    (at your option) any later version.

#   This program is distributed in the hope that it will be useful,
#   but WITHOUT ANY WARRANTY; without even the implied warranty of
#   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#   GNU General Public License for more details.

#   You should have received a copy of the GNU General Public License
#   along with this program.  If not, see <http://www.gnu.org/licenses/>.

import re
import numpy as np
from sys import argv
import matplotlib
matplotlib.use('Agg')
from matplotlib import pyplot as plt
import logging
import networkx as nx
from scipy.optimize import curve_fit
from scipy.optimize import fsolve
import argparse 

# Parametric sigmoid function for fitting
def sigmoid(x, x0, k, m, n): 
     y = m / (1 + np.exp(k*(x-x0))) + n
     return y

# Parametric analytic second derivative of sigmoid 
def seconddevsigmoid(x, x0, k, l, m): 
    y = ( k**2 * l * np.exp(k*(x+x0)) * ( np.exp(k*x)-np.exp(k*x0) )  )   /   ( np.exp(k*x0) + np.exp(k*x) )**3    
    return y    

parser = argparse.ArgumentParser(description='find persistence critical value')
    
parser.add_argument('-d','--input-dat', dest='datfiles', help='dat file matrices (multiple: -d file.dat -d file2.dat ...)',action='append')
parser.add_argument('-o','--output-dat', dest='out_dat', help='output dat file matrix', action='store', type=str, default=None)
parser.add_argument('-c','--output-clusters', dest='out_clusters', help='output clusters file', action='store', type=str, default=None)
parser.add_argument('-t','--filter-threshold', dest='filter', type=float, default=0.0, help='filter input matrices according to this threshold')
parser.add_argument('-p','--plot', dest='plot', default=None, help='Plot clusters')
parser.add_argument('-f','--fit', dest='do_fit', default=False, action='store_true', help='Try to fit the plot to a sigmoid y = m / (1 + exp(k*(x-x0))) + n')
parser.add_argument('-u','--range-upper', dest='upper', default=100.0, type=float, help='Maxium range value to be considered')
parser.add_argument('-l','--range-lower', dest='lower', default=0.0, type=float, help='Minimum range value to be considered')
parser.add_argument('-s','--range-step', dest='step', default=5.0, type=float, help='step range value to be considered')
parser.add_argument('-w','--weight-matrix', dest='weights', help='Use values in this matrix as weights for the output adjacency matrix',action='store', type=str)

parser.add_argument("-x","--x0", dest='x0',default=20.0, help='starting x0 parameter for sigmoid fitting (default: 20.0)',  type=float)
parser.add_argument('-k',        dest='k', default=2.0,  help='starting k parameter for sigmoid fitting (default: 2.0)',  type=float)
parser.add_argument('-m',        dest='m', default=20.0, help='starting m parameter for sigmoid fitting (default: 20.0)',  type=float)
parser.add_argument('-n',        dest='n', default=10.0, help='starting n parameter for sigmoid fitting (default: 10.0)',  type=float)

options = parser.parse_args()

if not options.datfiles:
     logging.error("input file(s) must be provided.")
     exit(1)

if options.upper <= options.lower:
     logging.error("maximum range value must be higher than minimum.")
     exit(1)

if options.step > (options.upper - options.lower):
     logging.error("step value must be lower than or equal to [upper_value - lower_value]")
     exit(1)

fnames=options.datfiles

matrices = []


for fname in options.datfiles:
     try:
          matrices.append(np.loadtxt(fname))
     except:
          logging.error("could not open file %s, or file in wrong format" %fname)
          exit(1)

shapes = []
for i in matrices:  shapes.extend(i.shape)
if len(set(shapes)) != 1:
    logging.error("matrices do not have the same shape.")
    exit(1)

for i in range(len(matrices)):
    for j in range(matrices[i].shape[0]):
        for k in range(matrices[i].shape[1]):
            if matrices[i][j,k] != matrices[i][k,j]:
                logging.error("matrix %s is not square" % (fnames[i]))
                exit(1)
            if j == k and matrices[i][j,k] > 0.0:
                #logging.warning("diagonal element in matrix %s (%d,%d) > 0.0. Will not be considered." % (fnames[i],j,k))
                matrices[i][j,k] = 0.0

vals = np.arange(options.lower, options.upper, options.step)

maxclustsize = []

for val in vals:       
    boolmats = [i>val for i in matrices]
    allmat = boolmats[0]
    if len(boolmats) > 1:
        for i in range (1,len(boolmats)):
             allmat = np.logical_or(allmat, boolmats[i])

    G=nx.Graph(allmat)
    maxclustsize.append(len(max(list(nx.algorithms.components.connected_components(G)), key=len)))

x = vals
y = maxclustsize

args = None
flex = None

if options.do_fit:
     logging.info("""Fitting data points to functional form: y = l / (1 + exp(k*(x-x0))) + m
Starting parameters:
    x0 = %3.2f 
    k =  %3.2f 
    m =  %3.2f  
    n =  %3.2f""" % (options.x0, options.k, options.m, options.n))

     try:
          popt, pcov = curve_fit(sigmoid, x, y, maxfev=100000, p0=(options.x0, options.k, options.m, options.n) )
          args=(popt[0],popt[1],popt[2],popt[3])
     except:
          logging.error("could not complete fitting.")
          args = None

     flex = None
     if args:
          logging.info("""
Done!
Calculated parameters: 
    x0 = %3.5f
    k  = %3.5f
    l  = %3.5f
    m  = %3.5f""" % (args[0],args[1],args[2],args[3]))

          logging.info("Looking for central point of inflection (f''(x) = 0) ...")

          solvestart = options.x0

          logging.info("Starting from: %3.5f ..." % solvestart) 

          try:
               flex = fsolve(seconddevsigmoid,solvestart,args=args,maxfev=5000)    
          except:
               flex = None

          if flex:
               print "Flexus point at %3.2f" % flex

if options.plot:
     plt.plot(x, y, 'o')

     plt.xlim((options.lower, options.upper))
     plt.xlabel("$p_{min}$")
     plt.ylabel("Size of the biggest cluster")
     if args:
          xplot = np.linspace(max(x),min(x))
          yplot = sigmoid(xplot, *popt)
          plt.plot(xplot, yplot, label='Fitting')
         
     if flex:
          plt.plot(flex,sigmoid(flex,*popt),'o',label = 'Critical value', color = 'red')
          plt.axvline(x=flex)

     plt.legend(loc='best')
     plt.savefig(options.plot)

if options.out_clusters:
    try:
        fh = open(options.out_clusters, 'w')
        fh.write("P_min\tSize of biggest cluster\n")
    except:
        logging.error("Could not write clusters file.")
	exit(1)
    for i, xi in enumerate(x):
        fh.write("%.3f\t%d\n" % (xi, y[i]))
    fh.close()

if options.out_dat:
    if len(matrices) == 1:         
         mask = matrices[0] <= options.filter
         out_matrix = np.ma.masked_array(data=matrices[0], mask = mask, fill_value=0.0).filled()
    else:
         boolmats = [i > options.filter for i in matrices]
         out_matrix = boolmats[0]
         for i in range (1,len(boolmats)):
             out_matrix = np.logical_or(out_matrix, boolmats[i])
    if options.weights:
         try:
              weights = np.loadtxt(options.weights)
         except:
              logging.error("Could not read weights matrix.")
              exit()
         
         if weights.shape != out_matrix.shape:
              logging.error("Output and weight matrix have different shapes.")

         np.savetxt(options.out_dat, np.ma.masked_array(data=weights, mask=out_matrix > 0.0, fill_value = 0.0).filled(), fmt="%3.2f")

    else:
         np.savetxt(options.out_dat, out_matrix,fmt="%3.2f")
