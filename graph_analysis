#!/usr/bin/python
# -*- coding: utf-8 -*-

#    PyInteraph, a software suite to analyze interactions and interaction network in structural ensembles.
#    Copyright (C) 2013 Matteo Tiberti <matteo.tiberti@gmail.com>, Gaetano Invernizzi, Yuval Inbar,
#    Matteo Lambrughi, Gideon Schreiber, Â Elena Papaleo <elena.papaleo@unimib.it> <elena.papaleo@bio.ku.dk>
#
#    This program is free software: you can redistribute it and/or modify
#    it under the terms of the GNU General Public License as published by
#    the Free Software Foundation, either version 3 of the License, or
#    (at your option) any later version.

#   This program is distributed in the hope that it will be useful,
#   but WITHOUT ANY WARRANTY; without even the implied warranty of
#   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#   GNU General Public License for more details.

#   You should have received a copy of the GNU General Public License
#   along with this program.  If not, see <http://www.gnu.org/licenses/>.

from __future__ import absolute_import
import sys

major, minor, patch  = sys.version_info
if major < 2 or (major == 2 and minor < 7):
	errstr = \
		"Your Python version is {:s}, but only " \
		"versions >= 2.7 are supported."
	log.error(errstr.format(sys.version))
	exit(1)

import argparse
import logging as log
import numpy as np
import networkx as nx
import MDAnalysis as mda
from Bio import PDB

########################### ARGUMENT PARSER ###########################

description = "PyInteraph network analysis module."
parser = argparse.ArgumentParser(description = description)

parser.add_argument("-r","--reference", \
					metavar = "TOPOLOGY", \
					dest = "top", \
					type = str, \
					help = "Reference topology file", \
					default = None)

parser.add_argument("-a","--adj-matrix", \
					metavar = "DAT", \
					dest = "dat", \
					type = str, \
					help = "Input graph file")

parser.add_argument("-c","--components", \
	                dest = "do_components", \
	                action = "store_true", \
	                default = False, \
	                help = "Calculate connected components")

parser.add_argument("-u","--hubs", \
	                dest = "do_hubs", \
	                action = "store_true", \
	                default = False, \
	                help = "Calculate hubs")

parser.add_argument("-k","--hubs-cutoff", \
	                dest = "hubs_cutoff", \
	                default = 4, \
	                type = int, \
	                help = "Minimum number of connections for hubs")

parser.add_argument("-p","--all-paths", \
	                dest = "do_paths", \
	                action = "store_true", \
	                default = False, \
	                help = "Calculate all simple paths between " \
	                       "two residues in the graph")

parser.add_argument("-r1","--source", \
	                dest = "source", \
	                default = None, \
	                help = "First residue for paths calculation " \
	                	   "(see option -p)")

parser.add_argument("-r2","--target", \
					dest = "target", \
					default = None, \
					help = "Last residue for paths calculation " \
						   "(see option -p)")

parser.add_argument("-l","--maximum-path-length", \
					dest = "maxl", \
					default = 3, \
					type = int, \
					help = "Maximum path length (see option -p)")

parser.add_argument("-s","--sort-paths", \
					dest = "sort_paths_by", \
					choices = ["length", "cumulative_weight", "avg_weight"], \
					default = "length", \
					help = "How to sort pathways in output (default: length)")

parser.add_argument("-cb","--components-pdb", \
					dest = "components_pdb", \
					default = None, \
					help = "Save connected components ID in PDB file")

parser.add_argument("-ub","--hubs-pdb", \
					dest = "hubs_pdb", \
					default = None, \
					help = "Save hub degrees in PDB file")

parser.add_argument("-d","--write-paths", \
					dest = "write_paths", \
					default = False, \
					action = "store_true")

args = parser.parse_args()

def residue_key(x):
	return int("".join(list(filter(str.isdigit, str(x)))))

def build_graph(fname, pdb = None):
	try:
		data = np.loadtxt(fname)
	except:
		errstr = \
			"Could not load file {:s} or wrong file format. Exiting..."
		# log the full numpy stack trace with exc_info
		log.error(errstr.format(fname), exc_info = True)
		exit(1)

	if pdb is not None:
		try:
			# generate a Universe object from the PDB file
			# (use the PDB for both the 'topology' and 'trajectory'
			# arguments necessary to create the Universe)
			u = mda.Universe(pdb, pdb)
		except Exception:
			errstr = \
				"Exception caught during creation of the Universe " \
				"object. Exiting..."
			# log the full MDAnalysis stack trace with exc_info
			log.error(errstr, exc_info = True)
		
		identifiers = \
			["{:s}-{:d}{:s}".format(r.segment.segid, \
									r.resnum, \
									r.resname) \
			 for r in u.residues]
 
	else:
		# generate automatic identifiers going from 1 to the
		# total number of residues considered
		identifiers = [str(name) for name in range(1,data.shape[0]+1)]
	
	# generate a graph from the data loaded
	G = nx.Graph(data)

	# set the names of the graph nodes (in place)
	node_names = dict(zip(range(data.shape[0]), identifiers))
	nx.relabel_nodes(G, mapping = node_names, copy = False)

	return identifiers, G

def get_connected_components(G):
	return nx.connected_components(G)


def get_hubs(G, min_k=4):
	hubs = dict()
	for key,val in nx.degree(G).iteritems():
		if val >= min_k:
			hubs[key] = val

	return hubs

def get_all_paths(G, source, target, cutoff=None): # From Networkx 1.9.dev_20130728171020

    if cutoff is None:
        cutoff = len(G)-1

    visited = [source]
    stack = [iter(G[source])]

    while stack:
        children = stack[-1]
        child = next(children, None)
        if child is None:
            stack.pop()
            visited.pop()
        elif len(visited) < cutoff:
            if child == target:
                yield visited + [target]
            elif child not in visited:
                visited.append(child)
                stack.append(iter(G[child]))
        else: #len(visited) == cutoff:
            if child == target or target in children:
                yield visited + [target]
            stack.pop()
            visited.pop()

def values_to_bfac(pdb, vals, pdb_out):
	parser = PDB.PDBParser()
	structure = parser.get_structure('protein',pdb)
	io = PDB.PDBIO()
        chain_offset = 0
	for model in structure:
		for chain in model:
			for i,residue in enumerate(chain):
				for atom in residue:
					atom.set_bfactor(float(vals[i+chain_offset]))
			chain_offset += len(chain)

	io.set_structure(structure)
	io.save(pdb_out)

if not args.dat:
    print "ERROR: Graph adjacency matrix must be specified. Exiting..."
    exit(1)
if (args.components_pdb or args.hubs_pdb) and not args.top:
	print "ERROR: a pdb reference file must be supplied with options -cb and -ub. Exiting..."

identifiers, G = build_graph(args.dat, pdb=args.top)

print "Graph loaded! %d nodes, %d edges" % (len(G.nodes()), len(G.edges()))
print "Node list:"
for i in sorted(G.nodes(), key=residue_key): 
	print "\t%s" % i

if args.do_components:
	ccs = list(get_connected_components(G))
	for i,cc in enumerate(ccs):
		print "Connected component %d:\n\t (%d elements)" % (i+1, len(cc)),
		print ", ".join(sorted(cc, key=residue_key))
	if args.components_pdb:
		conn_comp_array = np.array(identifiers)
		for i,cc in enumerate(ccs):
			for res in cc:
				conn_comp_array[identifiers.index(res)] = i+1
		values_to_bfac(args.top, conn_comp_array, args.components_pdb)
		
if args.do_hubs:
	hubs = get_hubs(G, min_k=args.hubs_cutoff)
	if len(hubs.keys()) > 0:
		print "Hubs:"
		print "\tNode\tk"
		sorted_hubs = sorted(hubs.items(), key=lambda x: x[1], reverse=True)

		for el in sorted_hubs:
			print "\t%s\t%d" % (el[0],el[1])
	else:
		print "No hubs with connectivity >= %d have been found." % args.hubs_cutoff
	if args.hubs_pdb:
                hubs_array = np.zeros(len(identifiers))
		hubs_dict = dict(sorted_hubs)
		for i,idt in enumerate(identifiers):
			try:
				hubs_array[i] = hubs_dict[idt]
			except:
                                pass
                values_to_bfac(args.top, hubs_array, args.hubs_pdb)	
		
if args.do_paths:
	if not args.source or not args.target:
		print "ERROR: You must specify source and target residues. Exiting..."
	if not args.source in G.nodes() or not args.target in G.nodes():
		print "ERROR: source or target residues have been badly specified. Exiting..."
	try:
		shortest = nx.algorithms.shortest_path(G, args.source, args.target)
	except:
		print "ERROR: No paths exist between selected residues."
		exit(1)
	if len(shortest) == 0:
		print "No paths exist between source and target."
		exit(1)
	elif len(shortest) > args.maxl:
		print "No paths were found between the given nodes at the give cut-off. Shortest path length beetween these two nodes is: %d" % len(shortest)
	else:
		paths_g = get_all_paths(G, args.source, args.target, cutoff=args.maxl)
		paths = [p for p in paths_g]
		lengths = [ len(p) for p in paths ]
		sum_weights = [ np.sum([ G[p[i]][p[i+1]]['weight'] for i in range(len(p)-1) ]) for p in paths ]
		avg_weights = [ np.average([ G[p[i]][p[i+1]]['weight'] for i in range(len(p)-1) ]) for p in paths ]

		full_paths = zip(paths, lengths, sum_weights, avg_weights)
		
		reverse = True
		
		if args.sort_paths_by == 'length':
			key = lambda x: x[1]
			reverse = False
			
		elif args.sort_paths_by == 'cumulative_weight':
			key = lambda x: x[2]

		elif args.sort_paths_by == 'avg_weight':
			key = lambda x: x[3]

		sorted_paths = sorted(full_paths, key=key, reverse=reverse)

		print "Path #\tLength\tSum of weights\tAverage weight\tPath"
		for i,p in enumerate(sorted_paths):
			print "%d\t%d\t%.1f\t\t%.1f\t\t%s" % (i+1,p[1],p[2],p[3],",".join(p[0]))
		if args.write_paths:
			for i,p in enumerate(sorted_paths):
				this_a = np.zeros(nx.adjacency_matrix(G).shape)
				for e in range(len(p[0])-1):
					x = identifiers.index(p[0][e])
					y = identifiers.index(p[0][e+1])
					this_a[x,y] = G[p[0][e]][p[0][e+1]]['weight']
					this_a[y,x] = G[p[0][e+1]][p[0][e]]['weight']
				np.savetxt("path_%d.dat" % (i+1) , this_a, fmt="%.1f")

